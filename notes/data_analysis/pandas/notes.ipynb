{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. \n",
    "\n",
    "## Libraries For Data Science\n",
    "\n",
    "- Data scientists need to convert data into an easy-to-process format.\n",
    "- Python's native lists and dictionaries may not be efficient for large data sets.\n",
    "- NumPy is a fundamental package for scientific computation in Python.\n",
    "- NumPy provides useful mathematical operations, including matrix computation.\n",
    "- NumPy can be used as a multi-dimensional container of generic data and integrates seamlessly with a variety of databases.\n",
    "- SciPy is a library of software for engineering and science applications built on top of NumPy.\n",
    "- Statsmodels enables users to conduct data exploration via the use of various methods of estimation of statistical models and performing statistical assertions and analysis.\n",
    "- Pandas is a Python package designed to work with relational data and helps with data wrangling, manipulation, aggregation, and visualization.\n",
    "\n",
    "## Data Visualization\n",
    "\n",
    "- Data visualization is a common task for data scientists. \n",
    "- Python has good library support for data visualization with Matplotlib, Plotly, and Bokeh. \n",
    "- Matplotlib is a powerful and flexible plotting library for creating interactive 2D and 3D plots. \n",
    "- Seaborn is complementary to Matplotlib and specifically targets statistical data visualizations. \n",
    "- Scikit-Learn is a heavily used package for machine learning and offers a consistent interface to common ML algorithms.\n",
    "\n",
    "## Deep Learning - Keras/Tensorflow\n",
    "\n",
    "- Keras is a popular library for building neural networks in Python that builds on top of TensorFlow.\n",
    "- TensorFlow is an open-source library of data flow graph computations designed for heavy duty machine learning and can be used in real-world applications.\n",
    "- TensorFlow's multi-layered nodes system enables quick training of artificial neural networks on big data and powers Google's voice and object recognition.\n",
    "- Keras is easier to use for Python developers and is highly modular and extensible.\n",
    "- Despite its simplicity, Keras is still powerful enough for serious modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "\n",
    "have at least one example for each\n",
    "\n",
    "know what the info and dtypes methods show, what information they return, not just 'summary'\n",
    "\n",
    "## methods\n",
    "\n",
    ".head() - first n rows, default 5\n",
    "\n",
    ".tail() - last n rows, default 5\n",
    "\n",
    ".info() - summary of the dataframe\n",
    "\n",
    "## attributes\n",
    ".index - access the row labels of the dataframe\n",
    "\n",
    ".columns - access the column labels of the dataframe\n",
    "\n",
    ".dtypes - returns the datatypes of all columns in the dataframe\n",
    "\n",
    ".shape - returns a tple representing the dimensionality of the dataframe, (rows, columns)\n",
    "\n",
    "## Selecting Dataframe Information\n",
    "\n",
    ".iloc - pandas dataframe indexer used for integer-location based indexing/selection by position\n",
    "\n",
    ".loc - select by label/index or selecting with a boolean/conditional lookup\n",
    "\n",
    "\n",
    "### .iloc examples\n",
    "\n",
    "df.iloc[0] - returns single row\n",
    "\n",
    "df.iloc[0:5] - returns several rows\n",
    "\n",
    "df.iloc[0:5, 0:2] - returns range of rows and range of columns [row, columns]\n",
    "\n",
    "df.iloc[:, 3:7] - selects all rows, and columns 3-6\n",
    "\n",
    "\n",
    "### .loc examples\n",
    "\n",
    ".loc is label-based indexing\n",
    "\n",
    "df.loc[0] - can be used to select columns based on their row index and column names\n",
    "\n",
    "df.loc[:, 'magnesium'] - returns all rows for the magnesium column\n",
    "\n",
    "An alternative method here is simply calling `df['magnesium']`!\n",
    "\n",
    "df.loc[7:16, 'magnesium'] - returns rows 7-16 for the magnesium column\n",
    "\n",
    "accessing multiple columns:\n",
    "\n",
    "df.loc[5:9, ['Home Team Name', 'Away Team Name']]\n",
    "\n",
    "#### Boolean Indexing using .loc\n",
    "\n",
    "Allows you to select certain rows based on the value of a variable.\n",
    "\n",
    "df.loc[df['alcohol'] < 12] - creates a new dataframe that only contains the wines with an alcohol percentage below 12\n",
    "\n",
    "`df[df['alcohol'] < 12]` give the same result\n",
    "\n",
    "However, the .`loc` attribute is useful if you'd only want the color intensity for the wines with an alcohol percentage below 12. You can obtain the result as follows:\n",
    "\n",
    "df.loc[df['alcohol'] < 12, ['color_intensity']]\n",
    "\n",
    "## Selectors for series\n",
    "\n",
    "extracting one column from a dataframe object and assigning to a variable turns it into a series object\n",
    "\n",
    "col_intensity[0:3]\n",
    "\n",
    "col_intensity[col_intensity > 8] \n",
    "\n",
    "Or col_intensity.loc[col_intensity > 8]\n",
    "\n",
    "## Changing and setting values in dataframes and series\n",
    "\n",
    "Imagine that for some reason, you're not interested in the color intensity values for color intensities above 10, and simply want to set all color intensities to 10 when they are bigger than 10. You can use a selector method and then assign it a new value, just like this:\n",
    "\n",
    "df.loc[df['color_intensity'] > 10, 'color_intensity'] = 10\n",
    "\n",
    "### Creating new columns\n",
    "Now imagine that we want to create a new column named, \"shade\" which has a value, \"light\" when the `color_intensity` is below 7, and, \"dark\" when the intensity is > 7. This can be done as follows:\n",
    "df.loc[df['color_intensity'] > 7, 'shade'] = 'dark'\n",
    "df.loc[df['color_intensity'] <= 7, 'shade'] = 'light'\n",
    "\n",
    "\n",
    "`df[(condition1) | (condition2)]`  -> Returns rows where either condition is true\n",
    "\n",
    "`df[(condition1) & (condition2)]`  -> Returns rows where both conditions are true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 importing using pandas\n",
    "\n",
    "- Learned how to import from CSV, Excel, and JSON file formats\n",
    "- Different functions for importing data (e.g. pd.read_csv(), pd.read_excel(), pd.read_json(), pd.DataFrame.from_dict())\n",
    "- Handle skipping and limiting rows during import using skiprows and nrows parameters\n",
    "- Deal with encoding issues using the encoding parameter\n",
    "- Select specific columns or sheets from imported data using usecols and sheet_name parameters\n",
    "- Load entire Excel workbooks and preview sheet names using pd.ExcelFile()\n",
    "- Saw how to export data back to files using to_csv() and to_excel() methods of DataFrame objects\n",
    "- Efficiently read data into Pandas DataFrames, manipulate and analyze the data, and save results back to files when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asdf"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
